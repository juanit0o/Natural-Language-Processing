{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from bertviz_repo.bertviz import model_view, head_view\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import auxLoadFilesAndDictionaries\n",
    "import pandas as pd\n",
    "import graficos as graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model to use\n",
    "#old model\n",
    "#model_path = 'bert-base-uncased'\n",
    "\n",
    "CLS_token = \"[CLS]\"\n",
    "SEP_token = \"[SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f065ffd59541c98eb025b0c1739e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a0946f602b4294a9ae8489fc56bb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6f8d4c691743479c5b614cdba6a1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "config = AutoConfig.from_pretrained('emilyalsentzer/Bio_ClinicalBERT',  output_hidden_states=True, output_attentions=True)  \n",
    "model = AutoModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load cases (patients)\n",
    "cases = pickle.load( open( \"cases_3.bin\", \"rb\" ) )\n",
    "\n",
    "#Load clinical trials detailed description\n",
    "dic_detail = pickle.load( open( \"dictionarydetailedDocs.bin\", \"rb\" ) )\n",
    "\n",
    "#A small query\n",
    "query = cases['20141'].strip()\n",
    "\n",
    "#Relevant Document for that query\n",
    "doc_rel= dic_detail['NCT00683813'][:200]\n",
    "#NonRelevant Document for that query\n",
    "doc_Nrel=dic_detail['NCT00077948'][:200]\n",
    "\n",
    "sentence_rel=[query,doc_rel]\n",
    "sentence_Nrel=[query,doc_Nrel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode to ids\n",
    "inputsRelevant = tokenizer.encode_plus(query, doc_rel, return_tensors='pt', add_special_tokens=True)\n",
    "inputsNonRelevant = tokenizer.encode_plus(query, doc_Nrel, return_tensors='pt', add_special_tokens=True)\n",
    "\n",
    "print(inputsRelevant)\n",
    "print(inputsNonRelevant)\n",
    "#decode back to words\n",
    "print(tokenizer.decode(inputsRelevant[\"input_ids\"][0].tolist()))\n",
    "print(tokenizer.decode(inputsNonRelevant[\"input_ids\"][0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_idsRelevant = inputsRelevant['input_ids']\n",
    "input_idsNonRelevant = inputsNonRelevant['input_ids']\n",
    "\n",
    "#only type tokenized ids of words\n",
    "print(input_idsRelevant[0].tolist())\n",
    "print(input_idsNonRelevant[0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check tokens made with the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relevant\n",
    "input_id_listRelevant = input_idsRelevant[0].tolist() # Batch index 0\n",
    "tokensRelevant = tokenizer.convert_ids_to_tokens(input_id_listRelevant)\n",
    "print(tokensRelevant)\n",
    "\n",
    "#Non Relevant\n",
    "input_id_listNonRelevant = input_idsNonRelevant[0].tolist() # Batch index 0\n",
    "tokensNonRelevant = tokenizer.convert_ids_to_tokens(input_id_listNonRelevant)\n",
    "print(tokensNonRelevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#MODEL INFERENCE\n",
    "\n",
    "#Relevant\n",
    "outputsRelevant = model(**inputsRelevant)\n",
    "attentionRelevant = outputsRelevant[-1]\n",
    "\n",
    "#Non Relevant\n",
    "outputsNonRelevant = model(**inputsNonRelevant)\n",
    "attentionNonRelevant = outputsNonRelevant[-1]\n",
    "\n",
    "#TODO ver o que significam as variaveis\n",
    "print(len(attentionRelevant[2]))\n",
    "print(len(attentionRelevant[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_idx(sent: str, word: str):\n",
    "    return sent.split(\" \").index(word)\n",
    "\n",
    "def get_hidden_states(encoded, token_ids_word, model, layers):\n",
    "    \"\"\"Push input IDs through model. Stack and sum `layers` (last four by default).\n",
    "        Select only those subword token outputs that belong to our word of interest\n",
    "        and average them.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded)\n",
    "\n",
    "     # Get all hidden states\n",
    "    states = output.hidden_states\n",
    "    # Stack and sum all requested layers\n",
    "    output = torch.stack([states[i] for i in layers]).sum(0).squeeze()\n",
    "    # Only select the tokens that constitute the requested word\n",
    "    word_tokens_output = output[token_ids_word]\n",
    "\n",
    "    return word_tokens_output.mean(dim=0)\n",
    "\n",
    "\n",
    "def get_word_vector(sent, idx, tokenizer, model, layers):\n",
    "    \"\"\"Get a word vector by first tokenizing the input sentence, getting all token idxs\n",
    "       that make up the word of interest, and then `get_hidden_states`.\"\"\"\n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\")\n",
    "#     print(encoded)\n",
    "    # get all token idxs that belong to the word of interest\n",
    "    token_ids_word = np.where(np.array(encoded.word_ids()) == idx)\n",
    "#     print(token_ids_word)\n",
    "    return get_hidden_states(encoded, token_ids_word, model, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pca_scatterplot(words_doc):\n",
    "    lista_palavras = words_doc.split(' ')\n",
    "    \n",
    "    #primeiro layer\n",
    "    layers=[0]\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    for i in lista_palavras[:10]:\n",
    "        idx=get_word_idx(words_doc,i)\n",
    "        #word embedding has 768 columns (attributes)\n",
    "        word_embedding=get_word_vector(words_doc,idx,tokenizer,model,layers)\n",
    "        print(len(word_embedding))\n",
    "        b=np.array(word_embedding)\n",
    "        c=np.reshape(b,(1,768))\n",
    "        X_tsne = TSNE(n_components=2, method='exact')\n",
    "        feat_tsne=X_tsne.fit_transform(c)\n",
    "        # aux = zip(lista_palavras[:10], feat_tsne[0])\n",
    "        # print(aux)\n",
    "        plt.scatter(feat_tsne[0][0], feat_tsne[0][1], edgecolors='k', c='r')\n",
    "        plt.text(feat_tsne[0][0], feat_tsne[0][1], i)\n",
    "\n",
    "            \n",
    "            \n",
    "    #ultimo layer        \n",
    "    layers= [-1]\n",
    "    for i in lista_palavras[:10]:\n",
    "        idx=get_word_idx(words_doc,i)\n",
    "        word_embedding=get_word_vector(words_doc,idx,tokenizer,model,layers)\n",
    "        b=np.array(word_embedding)\n",
    "        c=np.reshape(b,(1,768))\n",
    "        \n",
    "        X_tsne = TSNE(n_components=2, method='exact')\n",
    "        feat_tsne=X_tsne.fit_transform(c)\n",
    "\n",
    "        plt.scatter(feat_tsne[0][0], feat_tsne[0][1], edgecolors='k', c='b')\n",
    "\n",
    "        plt.text(feat_tsne[0][0], feat_tsne[0][1], i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n",
      "768\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO usar as palavras com mais attention\n",
    "#falar do que esta a contecer dentro de transformer\n",
    "display_pca_scatterplot(doc_rel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2 - Contextual embeddings visualization\n",
    "# Extract Token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_html():\n",
    "  import IPython\n",
    "  display(IPython.core.display.HTML('''\n",
    "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
    "        <script>\n",
    "          requirejs.config({\n",
    "            paths: {\n",
    "              base: '/static/base',\n",
    "              \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min\",\n",
    "              jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
    "            },\n",
    "          });\n",
    "        </script>\n",
    "        '''))\n",
    "\n",
    "    #Relevant\n",
    "\n",
    "    #utilizar uma parte do documento em vez de todo\n",
    "call_html()\n",
    "head_view(attentionRelevant, tokensRelevant)\n",
    "model_view(attentionRelevant, tokensRelevant)\n",
    "\n",
    "#Non Relevant\n",
    "call_html()\n",
    "head_view(attentionNonRelevant, tokensNonRelevant)\n",
    "model_view(attentionNonRelevant, tokensNonRelevant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bert_input(sentences, max_seq_length, tokenizer, add_cls, return_tensors=\"pt\"):\n",
    "\n",
    "    # The convention in BERT is:\n",
    "    # (a) For sequence pairs:\n",
    "    #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "    #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "    # (b) For single sequences:\n",
    "    #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "    #  type_ids: 0   0   0   0  0     0 0\n",
    "    #\n",
    "    # Where \"type_ids\" are used to indicate whether this is the first\n",
    "    # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "    # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "    # embedding vector (and position vector). \n",
    "    #\n",
    "    # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "    # used as as the \"sentence vector\".\n",
    "    \n",
    "    # Tokenize both sentences\n",
    "    sentences_tokens = [tokenizer.tokenize(s + SEP_token) for s in sentences]\n",
    "    \n",
    "    # Combine sentences tokens on a single list\n",
    "    tokens = sum(sentences_tokens, [])\n",
    "    \n",
    "    if add_cls:\n",
    "        tokens = [CLS_token] + tokens\n",
    "\n",
    "    # Create Token type ids tensors\n",
    "    token_type_ids = [[i]*len(s) for i, s in enumerate(sentences_tokens)] # Acount for the SEP token we've just added\n",
    "    token_type_ids = [0] + sum(token_type_ids, []) # CLS + The whole token_type_ids flattened\n",
    "\n",
    "    # Remove tokens if max_seq_length is exceeded\n",
    "    # Account for [CLS] and [SEP] with \"- 3\"\n",
    "    if len(tokens) > max_seq_length - 3:\n",
    "        tokens = tokens[:max_seq_length - 4] + [tokens[-1]] # keep SEP token\n",
    "        token_type_ids = token_type_ids[:max_seq_length - 3]\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "     # Create Attention mask tensor -> Which tokens should BERT consider\n",
    "    attention_mask = [1]*len(tokens)\n",
    "    \n",
    "    if return_tensors == \"pt\":\n",
    "        input_ids = torch.tensor([input_ids], dtype=torch.long)\n",
    "        token_type_ids = torch.tensor([token_type_ids], dtype=torch.long)\n",
    "        attention_mask = torch.tensor([attention_mask], dtype=torch.long)\n",
    "    \n",
    "    data = {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"token_type_ids\": token_type_ids,\n",
    "        \"attention_mask\": attention_mask\n",
    "    }\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query-Document relevant Heat-Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO NAO QUEREMOS O DA PRIMEIRA LAYER E O DA SEGUNDA, QUEREMOS E O INPUT E O OUTPUT DA PRIMEIRA\n",
    "\n",
    "sentences = [query, doc_rel]\n",
    "inputs_query_passages = convert_to_bert_input(sentences=sentences, max_seq_length=512, tokenizer=tokenizer, add_cls=True)\n",
    "#print(inputs_query_passages)\n",
    "decoded_input_qa = tokenizer.decode(inputs_query_passages[\"input_ids\"][0])\n",
    "# print(decoded_input_qa)\n",
    "outputs_qa = model(**inputs_query_passages)\n",
    "# print(outputs_qa)\n",
    "\n",
    "tokenizedSentence = decoded_input_qa\n",
    "lista_palavras = tokenizedSentence.split(' ')\n",
    "# newlista = []\n",
    "# for i in lista_palavras:\n",
    "#     if i != \"\" and len(i) >= 2:\n",
    "#         newlista.append(i)\n",
    "# print(newlista)\n",
    "# lista_palavras = newlista\n",
    "\n",
    "inputEmbeddings = []\n",
    "for token in lista_palavras:\n",
    "    idx=get_word_idx(tokenizedSentence,token)\n",
    "    word_embedding=outputs_qa[0][0][idx]\n",
    "    word_embedding=word_embedding.detach().numpy()\n",
    "    b=np.array(word_embedding)\n",
    "    c=np.reshape(b,(1,768))\n",
    "    inputEmbeddings.append(c)\n",
    "    #print(token)\n",
    "\n",
    "outputEmbeddings = []\n",
    "layers=[0]\n",
    "for token in lista_palavras:\n",
    "    idx=get_word_idx(tokenizedSentence,token)\n",
    "    word_embedding=get_word_vector(tokenizedSentence,idx,tokenizer,model,layers)\n",
    "    b=np.array(word_embedding)\n",
    "    c=np.reshape(b,(1,768))\n",
    "    outputEmbeddings.append(c)\n",
    "\n",
    "newInputEmbeddings = []\n",
    "for i in inputEmbeddings:\n",
    "    newInputEmbeddings.append(i[0])\n",
    "\n",
    "newOutputEmbeddings = []\n",
    "for i in outputEmbeddings:\n",
    "    newOutputEmbeddings.append(i[0])\n",
    "    \n",
    "\n",
    "\n",
    "# Declaring rows\n",
    "N = len(newInputEmbeddings)\n",
    "# Declaring columns\n",
    "M = len(newOutputEmbeddings)\n",
    "# using list comprehension \n",
    "# to initializing matrix\n",
    "matrixCorr = [ [ 0 for i in range(M) ] for j in range(N) ]\n",
    "\n",
    "import math\n",
    "\n",
    "for i in range(0, len(newInputEmbeddings)):\n",
    "    for j in range(0, len(newOutputEmbeddings)):\n",
    "        produto = np.dot(newInputEmbeddings[i], newOutputEmbeddings[j])\n",
    "        print(produto)\n",
    "        #TODO da nan no calculo dos ultimos output embeddings nao sei pq (estou a substituir os nans por 0)\n",
    "        if math.isnan(produto):\n",
    "            print(\"======\")\n",
    "            print(newInputEmbeddings[i])\n",
    "            print(newOutputEmbeddings[j])\n",
    "            produto = 0\n",
    "            print(\"======\")\n",
    "\n",
    "        matrixCorr[i][j] = produto\n",
    "\n",
    "# matrizMult = np.dot(newInputEmbeddings,newOutputEmbeddings)\n",
    "print(np.shape(matrixCorr))\n",
    "#nr linhas = nrLinhas primeira\n",
    "#nr colunas = nrColunas segunda\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "x_axis_labels = lista_palavras\n",
    "y_axis_labels = lista_palavras\n",
    "sns.heatmap(matrixCorr, xticklabels=x_axis_labels, yticklabels=y_axis_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query-Document NON-Relevant Heat-Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [query, doc_Nrel]\n",
    "inputs_query_passages = convert_to_bert_input(sentences=sentences, max_seq_length=512, tokenizer=tokenizer, add_cls=True)\n",
    "#print(inputs_query_passages)\n",
    "decoded_input_qa = tokenizer.decode(inputs_query_passages[\"input_ids\"][0])\n",
    "# print(decoded_input_qa)\n",
    "outputs_qa = model(**inputs_query_passages)\n",
    "# print(outputs_qa)\n",
    "\n",
    "tokenizedSentence = decoded_input_qa\n",
    "lista_palavras = tokenizedSentence.split(' ')\n",
    "# newlista = []\n",
    "# for i in lista_palavras:\n",
    "#     if i != \"\" and len(i) >= 2:\n",
    "#         newlista.append(i)\n",
    "# print(newlista)\n",
    "# lista_palavras = newlista\n",
    "\n",
    "inputEmbeddings = []\n",
    "for token in lista_palavras:\n",
    "    idx=get_word_idx(tokenizedSentence,token)\n",
    "    word_embedding=outputs_qa[0][0][idx]\n",
    "    word_embedding=word_embedding.detach().numpy()\n",
    "    b=np.array(word_embedding)\n",
    "    c=np.reshape(b,(1,768))\n",
    "    inputEmbeddings.append(c)\n",
    "    #print(token)\n",
    "\n",
    "outputEmbeddings = []\n",
    "layers=[0]\n",
    "for token in lista_palavras:\n",
    "    idx=get_word_idx(tokenizedSentence,token)\n",
    "    word_embedding=get_word_vector(tokenizedSentence,idx,tokenizer,model,layers)\n",
    "    b=np.array(word_embedding)\n",
    "    c=np.reshape(b,(1,768))\n",
    "    outputEmbeddings.append(c)\n",
    "\n",
    "newInputEmbeddings = []\n",
    "for i in inputEmbeddings:\n",
    "    newInputEmbeddings.append(i[0])\n",
    "\n",
    "newOutputEmbeddings = []\n",
    "for i in outputEmbeddings:\n",
    "    newOutputEmbeddings.append(i[0])\n",
    "    \n",
    "\n",
    "\n",
    "# Declaring rows\n",
    "N = len(newInputEmbeddings)\n",
    "# Declaring columns\n",
    "M = len(newOutputEmbeddings)\n",
    "# using list comprehension \n",
    "# to initializing matrix\n",
    "matrixCorr = [ [ 0 for i in range(M) ] for j in range(N) ]\n",
    "\n",
    "import math\n",
    "\n",
    "for i in range(0, len(newInputEmbeddings)):\n",
    "    for j in range(0, len(newOutputEmbeddings)):\n",
    "        produto = np.dot(newInputEmbeddings[i], newOutputEmbeddings[j])\n",
    "        print(produto)\n",
    "        #TODO da nan no calculo dos ultimos output embeddings nao sei pq (estou a substituir os nans por 0)\n",
    "        if math.isnan(produto):\n",
    "            print(\"======\")\n",
    "            print(newInputEmbeddings[i])\n",
    "            print(newOutputEmbeddings[j])\n",
    "            produto = 0\n",
    "            print(\"======\")\n",
    "\n",
    "        matrixCorr[i][j] = produto\n",
    "\n",
    "# matrizMult = np.dot(newInputEmbeddings,newOutputEmbeddings)\n",
    "print(np.shape(matrixCorr))\n",
    "#nr linhas = nrLinhas primeira\n",
    "#nr colunas = nrColunas segunda\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "x_axis_labels = lista_palavras\n",
    "y_axis_labels = lista_palavras\n",
    "sns.heatmap(matrixCorr, xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3870\n",
      "47\n",
      "12\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#todas combinacoes do qrels\n",
    "dicionarioPlotFinal = pickle.load( open( \"dicionarioPlotFinal.bin\", \"rb\" ) )\n",
    "print(len(dicionarioPlotFinal))\n",
    "\n",
    "\n",
    "test_query= set()\n",
    "for i in np.array(list(dicionarioPlotFinal.keys())):\n",
    "    test_query.add(i[0])\n",
    "\n",
    "class_train, class_test = train_test_split(np.array(list(test_query)),test_size = 0.20, random_state = 12)\n",
    "print(len(class_train))\n",
    "print(len(class_test))\n",
    "\n",
    "\n",
    "\n",
    "matriz_keys_test=[]\n",
    "matriz_feat_test=[]\n",
    "matriz_feat_train=[]\n",
    "matriz_keys_train=[]\n",
    "\n",
    "for k,v in dicionarioPlotFinal.items():\n",
    "    if k[0] in class_test:\n",
    "        matriz_keys_test.append(k)\n",
    "        matriz_feat_test.append(v)\n",
    "        #teste\n",
    "    else:\n",
    "        #treino\n",
    "        matriz_feat_train.append(v)\n",
    "        matriz_keys_train.append(k)\n",
    "        \n",
    "# print(matriz_keys_train)\n",
    "allaux = set()\n",
    "for i in matriz_keys_train:\n",
    "    allaux.add(i[0])\n",
    "print(len(allaux))\n",
    "#idquery, iddoc = 768 atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TREINO - calcular embeddings para os relevantes e nao relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589\n",
      "1535\n"
     ]
    }
   ],
   "source": [
    "#TODO standardizar e normalizar os dados\n",
    "\n",
    "#SO TREINO\n",
    "#ter uma lista de tuplos (query, doc) so com relevantes\n",
    "#so queremos as queries que tem detailed description - dic_detail\n",
    "\n",
    "allRelevants = []\n",
    "for i in matriz_keys_train:\n",
    "    for k,v in dic_detail.items():\n",
    "        if ((i[2] == '1') or (i[2] == '2')) and i[1] == k:\n",
    "            allRelevants.append((i[0], i[1], 1))\n",
    "print(len(allRelevants))\n",
    "\n",
    "#criar tuplo (query,doc), s os doc que tem detailed discption\n",
    "query_doc_rel=[]\n",
    "for k,v in dic_detail.items():\n",
    "    for i in allRelevants:\n",
    "        if k==i[1]:\n",
    "            query_doc_rel.append((i[0],i[1],i[-1]))\n",
    "\n",
    "\n",
    "allNonRelevants = []\n",
    "for i in matriz_keys_train:\n",
    "    for k,v in dic_detail.items():\n",
    "        if (i[2] == '0') and (i[1] == k):\n",
    "            allNonRelevants.append((i[0], i[1], 0))\n",
    "print(len(allNonRelevants))\n",
    "\n",
    "\n",
    "query_doc_nrel=[]\n",
    "for k,v in dic_detail.items():\n",
    "    for i in allNonRelevants:\n",
    "        if k==i[1]:\n",
    "            query_doc_nrel.append((i[0],i[1],i[-1]))\n",
    "\n",
    "# allQueryDocRelevant = [()]####\n",
    "# #todos os embeddings do cls (primeiro token) das queries-doc relevantes\n",
    "# #chave = (query, doc, score?? para calcular melhor c com crossv)\n",
    "# #valor = array de 768 atributos\n",
    "allRelevantEmbeddings = dict()\n",
    "#id query - id doc relevante\n",
    "for (queryID, documentoID,rel) in query_doc_rel:\n",
    "    query = cases[queryID]\n",
    "    doc_rel = dic_detail[documentoID]\n",
    "    doc_rel=doc_rel[:200]\n",
    "    \n",
    "\n",
    "    sentence_rel=[query,doc_rel]\n",
    "    inputs_query_passagesRelevant = convert_to_bert_input(sentences=sentence_rel, max_seq_length=512, tokenizer=tokenizer, add_cls=True)\n",
    "    decoded_input_qaRelevant = tokenizer.decode(inputs_query_passagesRelevant[\"input_ids\"][0])\n",
    "\n",
    "    outputs_qaRelevant = model(**inputs_query_passagesRelevant)\n",
    "    #cls embedding (first token) = has 768 features\n",
    "    # print(outputs_qaRelevant[0][0][0])\n",
    "    embeddingRelevante = outputs_qaRelevant[0][0][0]\n",
    "    embeddingRelevante = embeddingRelevante.detach().numpy()\n",
    "    allRelevantEmbeddings[(queryID, documentoID, rel)] = embeddingRelevante\n",
    "    \n",
    "\n",
    "\n",
    "allNonRelevantEmbeddings = dict()\n",
    "#query - doc nao relevante\n",
    "for (queryID, documentoID,rel) in query_doc_nrel:\n",
    "    queryText = cases[queryID]\n",
    "    doc_NrelText = dic_detail[documentoID]\n",
    "    doc_NrelText=doc_NrelText[:200]\n",
    "    \n",
    "    sentence_Nrel=[query,doc_Nrel]\n",
    "    inputs_query_passagesNonRelevant = convert_to_bert_input(sentences=sentence_Nrel, max_seq_length=512, tokenizer=tokenizer, add_cls=True)\n",
    "    decoded_input_qaNonRelevant = tokenizer.decode(inputs_query_passagesNonRelevant[\"input_ids\"][0])\n",
    "\n",
    "    outputs_qaNonRelevant = model(**inputs_query_passagesNonRelevant)\n",
    "    embeddingNaoRelevante = outputs_qaNonRelevant[0][0][0]\n",
    "    embeddingNaoRelevante = embeddingNaoRelevante.detach().numpy()\n",
    "\n",
    "    allNonRelevantEmbeddings[(queryID, documentoID, rel)] = embeddingNaoRelevante\n",
    "    \n",
    "\n",
    "#juntar tudo e fazer shuffle\n",
    "# allNonRelevantEmbeddings\n",
    "# allRelevantEmbeddings\n",
    "\n",
    "\n",
    "import random\n",
    "dictionaryAllEmbeddings = dict(list(allNonRelevantEmbeddings.items()) + list(allRelevantEmbeddings.items()))\n",
    "#shuffle dictionary\n",
    "\n",
    "shuffled = list(dictionaryAllEmbeddings.items())\n",
    "random.shuffle(shuffled)\n",
    "shuffledDictionary = dict(shuffled)\n",
    "\n",
    "#valores=[]\n",
    "# for i in shuffledDictionary.values():\n",
    "#     valores.append(i)\n",
    "\n",
    "# media=np.mean(valores, axis=1)\n",
    "# sd=np.std(valores)\n",
    "# for k,i in shuffledDictionary.items():\n",
    "#     shuffledDictionary[k]=(i-media)/sd\n",
    "\n",
    "# calcular os coeficientes com a log reg (com o melhor c)\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores=[]\n",
    "# for i in shuffledDictionary.values():\n",
    "#     valores.append(i)\n",
    "# valores=np.array(valores)\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(valores)\n",
    "# # media=np.mean(valores, axis=1)\n",
    "# # sd=np.std(valores)\n",
    "# for k,i in shuffledDictionary.items():\n",
    "#     i=i.reshape(1,768)\n",
    "#     shuffledDictionary[k]=scaler.transform(i)\n",
    "class_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcular o melhor C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "class_train = []\n",
    "feat_train = []\n",
    "for k,v in shuffledDictionary.items():\n",
    "    class_train.append(k[-1])\n",
    "    feat_train.append(v)\n",
    "\n",
    "\n",
    "def calc_fold_LR(X,Y, train_ix,valid_ix,c):\n",
    "    Log_regression1 = LogisticRegression(C=c, max_iter=10000)\n",
    "    X=np.array(X)\n",
    "    Y=np.array(Y)\n",
    "    Log_regression1.fit(X[train_ix],Y[train_ix])\n",
    "    t_e=1-Log_regression1.score(X[train_ix],Y[train_ix]) \n",
    "    v_e=1-Log_regression1.score(X[valid_ix],Y[valid_ix]) \n",
    "    return t_e, v_e\n",
    "\n",
    "range_c = np.arange(0.1,1,0.1)\n",
    "best_error = 10000\n",
    "best_c = 0\n",
    "train_error_list=[]\n",
    "valid_error_list=[]\n",
    "for c in range_c:\n",
    "    tr_err = va_err = 0\n",
    "    for tr_ix,va_ix in kf.split(class_train,class_train): \n",
    "        r,v = calc_fold_LR(feat_train,class_train,tr_ix,va_ix, c)\n",
    "        tr_err += r #erro de treino\n",
    "        va_err += v #erro de validacao, para escolher a melhor hipotese\n",
    "    \n",
    "    tr_err_mean =tr_err/5\n",
    "    va_err_mean =va_err/5\n",
    "    train_error_list.append(tr_err_mean)\n",
    "    valid_error_list.append(va_err_mean)\n",
    "    \n",
    "    if(best_error> va_err_mean):\n",
    "        best_error=va_err_mean\n",
    "        best_c=c\n",
    "print(best_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descobrir coeficientes com os dados de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.02949192e-02  8.26387563e-02  1.91650795e-02 -1.21867283e-02\n",
      " -7.96844604e-02  1.76196532e-01 -5.75108056e-02 -9.39572742e-02\n",
      " -1.66782063e-01  2.53697082e-02 -3.87178814e-02 -2.85181891e-02\n",
      "  9.18828947e-02 -6.88449274e-02  4.76287783e-02 -9.64651667e-03\n",
      "  5.21449943e-02  4.66514260e-02 -3.53846009e-02  1.69194175e-01\n",
      " -7.51166526e-03 -1.25315714e-01 -3.80985870e-02 -1.48720610e-01\n",
      " -2.47567855e-03  5.75536754e-02  5.82423838e-02  4.29172793e-02\n",
      " -8.92241968e-02  6.83135590e-02 -3.85551226e-03  8.79958504e-03\n",
      "  1.10731578e-01 -4.88108797e-02  6.73615954e-02  9.29755825e-02\n",
      " -4.75966880e-02 -1.03433674e-02  1.88181305e-02  2.78499556e-02\n",
      "  5.65107116e-02 -5.40971560e-02  2.25113753e-02  1.02598614e-01\n",
      "  1.30455083e-01  4.06989874e-02 -4.82161146e-02 -1.13084988e-01\n",
      " -4.44855848e-02  9.35578706e-02  9.06445531e-03 -4.75410131e-02\n",
      "  5.56611168e-03 -6.76071646e-03 -2.97219464e-02  4.74817104e-02\n",
      "  8.74256800e-02 -8.65614660e-02 -1.20242995e-01  6.55000019e-02\n",
      " -9.68226362e-04  2.28736761e-02 -2.44443766e-03  1.83413062e-02\n",
      "  1.50328152e-02 -1.46480890e-01 -9.12817734e-02  6.31072073e-02\n",
      " -2.36353518e-02 -1.18446725e-01  2.26311888e-02 -4.65242752e-02\n",
      "  3.75214402e-02 -5.85297281e-02  8.81906805e-02 -1.12384424e-01\n",
      "  1.25308410e-01  6.94298033e-02 -6.21034330e-02  4.60265490e-02\n",
      " -1.58330201e-01  9.22110306e-02  6.37871182e-02 -3.79007365e-02\n",
      " -1.47565898e-02  3.53384342e-05 -5.17240000e-02 -8.56523268e-02\n",
      "  2.79005927e-02  3.69441658e-02  9.50521268e-02  1.38798869e-02\n",
      " -6.27630680e-02  7.38756844e-02  6.82321829e-02 -2.67979171e-02\n",
      " -2.52736682e-02  1.30531407e-01 -7.05472158e-02  1.07389051e-01\n",
      "  2.37374438e-02  1.35979201e-02 -1.64022877e-01  6.68644991e-02\n",
      "  1.21847670e-02  4.28769080e-02  1.51571309e-01  2.87837817e-02\n",
      " -1.04911751e-01  2.26394891e-02  7.13568178e-03  1.14276633e-01\n",
      " -1.58611052e-01 -7.24978550e-02  1.74317243e-02 -7.30772453e-02\n",
      " -4.87880069e-02  2.54472460e-02  7.33401853e-02 -6.66309838e-02\n",
      "  1.50676927e-02  2.40990590e-02 -5.52393187e-02 -7.44046750e-02\n",
      "  5.43018962e-02 -1.95728313e-02  9.50503560e-03 -9.89498940e-03\n",
      "  2.87902578e-02  1.12589952e-03  2.30744158e-02  5.99606647e-03\n",
      " -2.34024098e-02  3.29976653e-02 -8.43237278e-02 -5.68315207e-02\n",
      " -1.52412529e-03 -2.37251145e-02  4.73295160e-02 -4.92632094e-03\n",
      " -1.70411920e-03  4.66789941e-02  7.11108913e-02  1.35260972e-01\n",
      "  6.55438696e-02 -8.70638621e-02 -6.53647046e-03  4.85729363e-02\n",
      "  2.77101008e-02 -2.10937582e-02  2.38762222e-02 -1.56128435e-02\n",
      " -8.37610420e-02  1.75769900e-02  1.17433888e-01  4.59837011e-02\n",
      "  5.67508710e-02  1.25448492e-02  5.58757981e-02  6.49968014e-02\n",
      "  1.05095535e-02  5.72614967e-03  4.29561143e-02 -1.36459096e-01\n",
      "  6.46125517e-02 -3.46788213e-02  1.37896219e-02 -6.94316826e-02\n",
      "  1.23666303e-01  2.44094994e-02  1.13117424e-02  2.15787503e-02\n",
      " -5.09272754e-02  6.54407784e-03 -2.68987115e-02 -7.52424060e-02\n",
      "  5.74591138e-02  3.28973237e-02 -7.84413332e-02  6.80840479e-02\n",
      " -4.74966160e-02  5.93692805e-02  7.83655218e-02 -1.14800170e-01\n",
      "  1.65947899e-01  6.78234514e-02  2.05623595e-03 -1.08704366e-01\n",
      "  7.91862023e-03  1.20687826e-01 -1.41906611e-01 -4.39437571e-02\n",
      " -5.94536348e-02 -1.92303714e-02 -7.98388853e-02 -3.68540767e-02\n",
      " -4.45392737e-02 -2.34017738e-01  6.51455083e-02  6.25471199e-02\n",
      "  7.34716676e-03 -2.98014149e-02 -3.53223705e-02  8.84066487e-02\n",
      " -2.16601311e-02  3.23858935e-02  2.76258349e-02  1.37088202e-02\n",
      "  1.63314393e-02 -3.34883169e-02 -6.74724980e-02  4.81233394e-02\n",
      " -4.13284811e-02 -6.47097103e-02 -1.30943680e-01  3.66891665e-02\n",
      "  1.97033751e-01 -2.63090716e-02  1.07728294e-01  9.58176648e-02\n",
      " -1.19266992e-02 -3.76822371e-02  7.30776181e-02  3.92322320e-02\n",
      "  4.30578245e-02 -7.23214536e-02  1.38562947e-02 -3.94397741e-02\n",
      " -7.37915821e-02 -2.73703454e-01  4.71453410e-02  1.15415680e-01\n",
      " -4.68181277e-02 -4.81939227e-02 -5.58670454e-03 -3.41080678e-02\n",
      " -6.37336134e-02 -1.79960149e-02 -7.36719385e-02 -3.24795869e-02\n",
      " -4.32285865e-02 -7.80107827e-02 -7.54890451e-02 -1.25641775e-01\n",
      " -7.73510009e-02 -4.52264355e-02  1.26136288e-01  9.08608282e-03\n",
      " -3.99321611e-02 -3.76323837e-02  2.21463605e-01  5.22701453e-02\n",
      " -2.62899984e-02 -2.60310400e-02  8.84020994e-02  1.65777515e-02\n",
      " -4.12672609e-03 -1.84234991e-02  6.92544752e-02 -3.15606383e-02\n",
      " -3.51603201e-02 -1.19981704e-02 -4.92022907e-02  1.46013449e-02\n",
      "  7.46717813e-02 -2.63688958e-02 -1.60202250e-01  4.26572623e-02\n",
      "  2.24063816e-02  2.33123349e-02 -6.66406573e-02 -9.15330646e-02\n",
      "  4.00051444e-02 -1.74716426e-02  1.35545726e-02 -1.16169886e-02\n",
      "  4.35863536e-02  6.14663046e-02  5.67149058e-02 -6.08534614e-02\n",
      " -2.72979497e-02  3.19819539e-02  3.49850502e-02 -4.48150891e-02\n",
      " -6.58024253e-02  6.38558666e-02  3.41744362e-02 -8.77078013e-02\n",
      "  6.43571808e-02 -6.23719743e-02  7.50050636e-02 -1.54027092e-02\n",
      "  1.16210870e-02  1.44978372e-02  2.93726566e-02  2.85040986e-02\n",
      " -4.20190220e-02 -3.97280757e-02 -4.71520191e-02 -1.32334952e-01\n",
      " -9.18917811e-02  2.97872453e-02 -6.94063507e-02 -4.86269883e-03\n",
      "  1.18697579e-01 -3.67320983e-02 -8.83658153e-02 -2.44752996e-02\n",
      " -3.60687943e-03  4.15468529e-02  5.51028308e-02  2.51461969e-02\n",
      " -5.92527600e-02 -8.85167627e-02 -2.25054288e-03  9.78910134e-02\n",
      " -8.90904822e-02 -6.03564148e-02  9.55751935e-02 -6.24651537e-02\n",
      "  2.85097756e-02  1.33040566e-01 -2.40547394e-01 -5.87745714e-02\n",
      " -4.66828544e-02 -8.84391512e-02 -8.26462480e-05 -7.64003071e-02\n",
      " -9.41186216e-02  1.06241057e-01  9.11956623e-02 -4.51406174e-02\n",
      "  2.78952234e-02  9.68542652e-03 -3.37442079e-02 -4.67641914e-04\n",
      " -7.08907470e-03 -4.95942142e-02 -4.06961198e-02 -1.06587910e-03\n",
      " -6.24498267e-02  2.40739660e-01  4.90990764e-03 -1.23869498e-01\n",
      " -6.20554785e-02 -2.05951806e-02 -1.23187051e-02 -1.65166939e-02\n",
      " -4.45927424e-02 -7.80200635e-02 -5.34690725e-02 -7.89471565e-02\n",
      "  2.11959727e-02 -2.16913016e-02 -5.21077023e-02  2.19877076e-02\n",
      "  1.32733557e-01 -6.86572544e-02 -5.07492847e-02  2.10333140e-02\n",
      " -9.27728686e-02 -6.88954295e-02 -2.29414841e-02 -1.04344535e-02\n",
      " -4.33630570e-02 -1.12675825e-01 -9.28144553e-02 -7.28130587e-04\n",
      "  2.42101938e-02 -4.65731769e-02 -5.76329510e-02  6.99216961e-02\n",
      "  2.84357449e-02  2.16455670e-02 -1.11598744e-01  4.42048629e-02\n",
      "  1.01380909e-01  2.52784106e-02 -1.00192555e-01  8.18298555e-02\n",
      " -3.57836426e-02  1.84639806e-02  1.72839297e-01 -1.39485569e-01\n",
      "  1.75108017e-02 -4.08853899e-02  1.10264955e-01  2.68977847e-02\n",
      "  6.70952808e-02 -1.65003411e-02 -2.98350643e-02 -1.13329123e-01\n",
      " -1.04890572e-02 -6.46774888e-02  2.61496020e-02  3.65418052e-02\n",
      "  3.70914551e-02  9.55768892e-02  4.16826571e-02 -5.43237642e-02\n",
      " -3.88811862e-02  5.45553638e-02  1.05157563e-01  9.70831263e-02\n",
      " -1.75338041e-02 -2.29852754e-02 -1.11679279e-02 -1.01892610e-01\n",
      " -2.54141853e-02  1.32762941e-02 -4.56799168e-02 -5.58116534e-02\n",
      " -1.85947823e-02 -6.42283955e-02 -1.38709557e-02  9.22538867e-04\n",
      "  1.79827446e-03  1.36493949e-01 -1.17186558e-01  2.02218829e-02\n",
      " -3.54769568e-02 -4.12937612e-02 -2.48746609e-03  3.05883048e-02\n",
      " -1.34291665e-01  8.68976760e-03 -4.53056041e-03 -1.74797480e-01\n",
      "  1.16147220e-01 -2.43601947e-02 -5.75024550e-02 -4.23728468e-02\n",
      "  2.23759980e-02  5.39043134e-03  9.82816556e-02 -2.09571210e-02\n",
      " -2.47385246e-02 -3.74129778e-02 -1.07322177e-01 -1.03608608e-01\n",
      "  2.40118144e-03 -2.22012979e-02 -4.99714514e-02  3.21821444e-02\n",
      " -1.07478485e-02  4.89233021e-02  4.95065172e-02  7.49257788e-02\n",
      " -1.28276608e-01 -2.70244100e-02 -2.11818411e-02 -1.50368476e-02\n",
      "  4.95185189e-02  2.52777997e-02 -1.69509315e-01  1.14268182e-01\n",
      " -4.55941120e-02  3.87720369e-02  5.86371825e-02  5.02166784e-02\n",
      " -3.97510964e-02  1.21229137e-01 -7.51484990e-02  5.19668424e-02\n",
      "  1.62713595e-02  7.94155257e-02  5.24212521e-02  8.11671649e-02\n",
      " -3.26843515e-02  7.97017815e-02  1.22034604e-02  9.66228012e-03\n",
      "  3.26912300e-02  7.76298993e-02  1.04174529e-03  4.88542463e-03\n",
      "  4.30957558e-02  1.01813256e-01  8.65492316e-02  2.51508959e-02\n",
      "  8.16319393e-02  4.27485344e-02 -4.61289271e-02  6.73959521e-02\n",
      "  1.59922923e-01  2.92840544e-02 -7.92146090e-02  4.55220377e-02\n",
      "  5.90062530e-02  3.63779332e-03  1.30546491e-01 -9.24203257e-02\n",
      " -2.62102094e-02  3.60505509e-02 -5.04051578e-02 -5.13988769e-02\n",
      "  1.03913460e-01  1.39246332e-02  1.88732344e-01  1.21895631e-02\n",
      " -1.77732054e-01  7.38386564e-02 -9.07908710e-02 -3.43869839e-02\n",
      " -8.33293795e-02  1.16935115e-02  1.42781326e-01  1.32886581e-01\n",
      "  4.17989661e-02 -1.79610282e-03  7.14941088e-02  4.58374831e-02\n",
      " -3.10976323e-02 -7.36265833e-02 -4.16172459e-02  2.34883892e-01\n",
      " -7.23806279e-02 -7.50243047e-02 -9.50207216e-02  4.36211107e-02\n",
      "  9.39599260e-02  5.12541565e-02 -1.65571223e-02  6.38295226e-02\n",
      "  2.42176057e-02  7.64786916e-02 -6.42983426e-03  1.10469094e-01\n",
      "  1.19661288e-01 -5.06684494e-02 -1.85015397e-02  1.55561088e-02\n",
      "  6.55578638e-02  1.13453281e-01 -2.10461142e-02 -6.18611838e-02\n",
      "  6.68712430e-02  1.07004276e-01  1.38751148e-03 -1.17452048e-02\n",
      " -3.85128954e-03 -1.25180378e-01 -3.64115820e-02 -8.52443001e-02\n",
      " -4.26326011e-02 -1.25396291e-01  9.64005890e-03  1.20951630e-01\n",
      " -5.70363283e-03  2.26529103e-02 -5.33301281e-02  9.83177046e-02\n",
      " -7.37058373e-02 -2.54668959e-02 -8.73948709e-02 -6.80566883e-02\n",
      "  7.25942678e-02 -1.08579958e-01  4.34900707e-02 -7.83588240e-02\n",
      " -3.11015903e-02  4.72955013e-02 -2.89234252e-02 -8.24516320e-02\n",
      " -5.61984259e-02  2.09591911e-01 -8.61324011e-02 -4.29050404e-02\n",
      "  4.90782882e-02 -2.61021093e-02 -5.85721899e-02  1.23970217e-02\n",
      "  4.34855128e-02  6.59537931e-02  2.28342399e-02  1.16287149e-01\n",
      "  4.28606915e-02  1.14858945e-01 -1.73530657e-02  1.53359776e-02\n",
      "  4.32980203e-02 -9.18197172e-03  4.17947264e-02  9.50674784e-03\n",
      "  1.00412711e-01 -6.07256588e-02  1.53042531e-01 -4.69436841e-02\n",
      "  3.83044892e-02 -4.17094095e-02  2.24302159e-02 -6.99527851e-02\n",
      " -1.25223952e-02 -1.25379655e-01  6.20108581e-02 -2.65946036e-02\n",
      "  3.52122452e-02 -1.04147252e-01  1.25397662e-01 -5.49962948e-02\n",
      "  4.17033795e-02 -5.33548148e-03 -8.99926052e-02 -1.89493019e-02\n",
      "  6.32709235e-02  8.17661856e-02 -9.15428776e-02 -6.78127150e-02\n",
      "  4.65195225e-02 -2.50177912e-02 -6.43086402e-03 -1.67341174e-01\n",
      " -3.92677447e-02  2.28446112e-01  5.89974296e-02  5.16444987e-02\n",
      "  6.39007945e-02  2.71401025e-02  1.32491373e-01  4.71006547e-02\n",
      " -5.36409951e-02 -1.63027499e-02  1.98545932e-02  4.92320043e-02\n",
      "  1.43305657e-01 -8.37461547e-04  4.21029435e-02  6.34181552e-02\n",
      " -4.67652220e-02 -4.52857997e-03  6.20082998e-02  3.01251373e-02\n",
      " -1.25225683e-01 -1.10624090e-01 -8.62158385e-02 -1.49296628e-03\n",
      " -6.98088746e-02  2.23002888e-02  6.99871375e-02  9.37970682e-03\n",
      " -7.16343211e-02  9.15609690e-02  8.57188743e-04  1.40667831e-02\n",
      "  4.02523206e-02  3.13124568e-02  1.15606206e-01 -5.92672738e-02\n",
      "  9.07306209e-03  2.97335075e-02 -3.58627258e-02  5.91449977e-02\n",
      "  2.41184479e-02  7.25454817e-02 -1.25798613e-01 -6.06369967e-02\n",
      "  8.61472661e-02  1.16131165e-01 -5.28485394e-02  5.16235414e-02\n",
      " -2.95947885e-02 -8.07129599e-02  3.60844660e-02  5.17773106e-02\n",
      " -6.66832137e-02 -1.00289536e-01 -6.14658511e-02  9.10936856e-02\n",
      " -8.49872960e-02 -1.26079277e-01  4.62103640e-02 -1.11525645e-01\n",
      " -2.60173418e-03 -4.95125188e-02  4.05263723e-02 -6.93180885e-02\n",
      "  3.73986291e-02 -2.21647054e-02 -4.56063946e-02  1.16755089e-01\n",
      " -1.12979604e-01 -1.05465135e-01 -8.97512787e-03 -4.62338213e-02\n",
      "  1.18984352e-01 -2.72113999e-02 -3.88355631e-02  8.94968975e-03\n",
      " -1.25625695e-01 -6.81097975e-02  4.14610154e-02 -4.68104028e-02\n",
      "  4.63459222e-02 -7.43697231e-03 -8.44338349e-02 -5.10581929e-02\n",
      " -1.85307407e-02  3.35737537e-02 -7.24875228e-02  6.35899714e-02\n",
      "  4.51844862e-02  4.77135823e-02 -9.40402800e-02  3.12883898e-02\n",
      " -1.60773565e-02  1.62133406e-02  7.66525028e-02  1.12563585e-02\n",
      " -1.24078611e-02 -2.17203294e-02 -3.21034119e-02  1.99534011e-02\n",
      " -7.01769435e-02 -3.27994558e-02 -4.11659990e-02  2.97914946e-03\n",
      "  8.10825711e-02  9.68499673e-02 -3.10587411e-02 -1.35325518e-03\n",
      "  8.15752982e-02 -6.98843658e-02 -2.52771287e-02  1.41157780e-02\n",
      " -1.05536791e-01  1.38821977e-01  3.10921871e-02 -2.42689689e-02\n",
      " -2.69783040e-02  2.30934325e-02  3.56880183e-02  6.77545381e-02\n",
      "  6.81248760e-02  4.17617298e-02  6.20457292e-02 -9.14952211e-02\n",
      " -4.45731636e-02  5.79292117e-02  4.00630010e-02 -7.85905141e-03\n",
      "  4.55415970e-03  5.05885262e-02 -6.16133277e-02 -1.53245159e-02\n",
      " -4.90397784e-02  8.43109745e-02 -8.91849697e-02  6.91848913e-02\n",
      "  5.54180583e-02  9.81356152e-02 -1.09016718e-03 -1.32871627e-02\n",
      " -8.29923171e-02  4.31679925e-02 -2.64174929e-01 -7.56088471e-02\n",
      "  2.04990689e-02 -5.57872774e-03  2.58298993e-02  5.11328791e-02\n",
      "  1.23890733e-02  1.24926118e-02  5.33482326e-02  1.00466305e-01\n",
      " -3.88521500e-02 -6.19518829e-02  5.60373022e-02  2.06849408e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "#tentar fazer cross validation para calcular o c caso tenhamos valores suficientes\n",
    "Log_regression1=LogisticRegression(max_iter = 10000, random_state=0, C = best_c)\n",
    "#separar feats e classes de treino\n",
    "\n",
    "Log_regression1.fit(feat_train,class_train)\n",
    "coeficientes = Log_regression1.coef_\n",
    "print(coeficientes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr de pacientes (queries): 60\n"
     ]
    }
   ],
   "source": [
    "dictionaryGendersQueries, dictionaryAgesQueries, vectorizerQueries, YQueries, eval = auxLoadFilesAndDictionaries.loadAux() \n",
    "docsGender, ids, docMaxAge, docMinAge, dictionaryGendersDocs, dictionaryAgesDocs = auxLoadFilesAndDictionaries.loadFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211\n",
      "388\n",
      "599\n"
     ]
    }
   ],
   "source": [
    "# Calcular embeddings para dados de teste\n",
    "\n",
    "dicionario_teste = dict()\n",
    "\n",
    "allRelevantsTest = []\n",
    "for i in matriz_keys_test:\n",
    "    for k,v in dic_detail.items():\n",
    "        if ((i[2] == '1') or (i[2] == '2')) and i[1] == k:\n",
    "            allRelevantsTest.append((i[0], i[1], 1))\n",
    "            \n",
    "print(len(allRelevantsTest))\n",
    "\n",
    "\n",
    "\n",
    "allNonRelevantsTest = []\n",
    "for i in matriz_keys_test:\n",
    "    for k,v in dic_detail.items():\n",
    "        if (i[2] == '0') and (i[1] == k):\n",
    "            allNonRelevantsTest.append((i[0], i[1], 0))\n",
    "print(len(allNonRelevantsTest))\n",
    "\n",
    "#calcular o embedding e preencgher o dicionario\n",
    "#################################################################\n",
    "\n",
    "allRelevantEmbeddingsTest = dict()\n",
    "#id query - id doc relevante\n",
    "for (queryID, documentoID, rel) in allRelevantsTest:\n",
    "    query = cases[queryID]\n",
    "    doc_rel = dic_detail[documentoID]\n",
    "    doc_rel=doc_rel[:100]\n",
    "\n",
    "    sentence_rel=[query,doc_rel]\n",
    "    inputs_query_passagesRelevant = convert_to_bert_input(sentences=sentence_rel, max_seq_length=512, tokenizer=tokenizer, add_cls=True)\n",
    "    decoded_input_qaRelevant = tokenizer.decode(inputs_query_passagesRelevant[\"input_ids\"][0])\n",
    "\n",
    "    outputs_qaRelevant = model(**inputs_query_passagesRelevant)\n",
    "    #cls embedding (first token) = has 768 features\n",
    "    # print(outputs_qaRelevant[0][0][0])\n",
    "    embeddingRelevante = outputs_qaRelevant[0][0][0]\n",
    "    embeddingRelevante = embeddingRelevante.detach().numpy()\n",
    "    allRelevantEmbeddingsTest[(queryID, documentoID, rel)] = embeddingRelevante\n",
    "    \n",
    "\n",
    "\n",
    "allNonRelevantEmbeddingsTest = dict()\n",
    "#query - doc nao relevante\n",
    "for (queryID, documentoID, rel) in allNonRelevantsTest:\n",
    "    queryText = cases[queryID]\n",
    "    doc_NrelText = dic_detail[documentoID]\n",
    "    doc_NrelText=doc_NrelText[:100]\n",
    "    sentence_Nrel=[query,doc_Nrel]\n",
    "    inputs_query_passagesNonRelevant = convert_to_bert_input(sentences=sentence_Nrel, max_seq_length=512, tokenizer=tokenizer, add_cls=True)\n",
    "    decoded_input_qaNonRelevant = tokenizer.decode(inputs_query_passagesNonRelevant[\"input_ids\"][0])\n",
    "\n",
    "    outputs_qaNonRelevant = model(**inputs_query_passagesNonRelevant)\n",
    "    embeddingNaoRelevante = outputs_qaNonRelevant[0][0][0]\n",
    "    embeddingNaoRelevante = embeddingNaoRelevante.detach().numpy()\n",
    "\n",
    "    allNonRelevantEmbeddingsTest[(queryID, documentoID, rel)] = embeddingNaoRelevante\n",
    "    \n",
    "\n",
    "#juntar tudo e fazer shuffle\n",
    "# allNonRelevantEmbeddings\n",
    "# allRelevantEmbeddings\n",
    "\n",
    "\n",
    "import random\n",
    "dictionaryAllEmbeddingsTest = dict(list(allNonRelevantEmbeddingsTest.items()) + list(allRelevantEmbeddingsTest.items()))\n",
    "#shuffle dictionary\n",
    "\n",
    "shuffledTest = list(dictionaryAllEmbeddingsTest.items())\n",
    "random.shuffle(shuffledTest)\n",
    "shuffledDictionaryTest = dict(shuffledTest)\n",
    "\n",
    "print(len(shuffledDictionaryTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516\n",
      "3626 3626 3626 3626 3626 3626\n",
      "60 60\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(shuffledDictionaryTest))\n",
    "print(len(docsGender), len(ids), len(docMaxAge), len(docMinAge), len(dictionaryGendersDocs), len(dictionaryAgesDocs))\n",
    "print(len(dictionaryGendersQueries), len(dictionaryAgesQueries))\n",
    "print(len(class_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shuffledDictionaryTest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2696b01d2ee4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshuffledDictionaryTest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'shuffledDictionaryTest' is not defined"
     ]
    }
   ],
   "source": [
    "shuffledDictionaryTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#queryID docID 668 features\n",
    "\n",
    "dicQueryDocs = dict()\n",
    "listaDocsFinal = []\n",
    "#scores para cada um dos triplos (qID, docID, score) \n",
    "#queremos (qID) => [docsIDs ordenados]\n",
    "\n",
    "allP10s,allMrr, allNdcg5, allAp, allRecall = ([] for i in range(5))\n",
    "avg_precision_11pointLETORUni = np.zeros(11)\n",
    "dictCaseIDP10 = dict()\n",
    "dictCaseAP = dict()\n",
    "#adicionar os (docID, scores) para cada query\n",
    "for i in class_test:\n",
    "    docScores = []\n",
    "    docIds = []\n",
    "    #Para cada triplo para fazer para cada doc com essa query\n",
    "    for k,v in shuffledDictionaryTest.items():\n",
    "        if k[0] == i:\n",
    "            #verificar se  do mm sexo ou da para os dois\n",
    "            if dictionaryGendersQueries[i] == dictionaryGendersDocs[k[1]] or dictionaryGendersDocs[k[1]] == \"Both\":\n",
    "                #verificar se idades batem certo:\n",
    "                #idade da query tem de ser maior ou igual a min age e menor ou igual a max age\n",
    "                ageQuery = int(dictionaryAgesQueries[i].replace(\" Years\", \"\"))\n",
    "                \n",
    "                ## MinAge\n",
    "                minAgeStudy = dictionaryAgesDocs[k[1]][0].replace(\" Years\", \"\").replace(\" Year\", \"\").replace(\"N/A\", \"-1\")\n",
    "                if len(minAgeStudy.split(\" \")) > 1:\n",
    "                    if (minAgeStudy.split(\" \")[1] == \"Months\") or (minAgeStudy.split(\" \")[1] == \"Month\") :\n",
    "                        #Caso tenha idade minima com meses\n",
    "                        minAgeStudy = int(minAgeStudy.split(\" \")[0])/12\n",
    "\n",
    "                    elif (minAgeStudy.split(\" \")[1] == \"Weeks\") or (minAgeStudy.split(\" \")[1] == \"Week\") :\n",
    "                        minAgeStudy = float(minAgeStudy.split(\" \")[0]) * 0.019165\n",
    "\n",
    "                    elif (minAgeStudy.split(\" \")[1] == \"Days\") or (minAgeStudy.split(\" \")[1] == \"Day\"):\n",
    "                        minAgeStudy = float(int(minAgeStudy.split(\" \")[0]) * 0.002738)\n",
    "                    elif (minAgeStudy.split(\" \")[1] == \"Hours\") or (minAgeStudy.split(\" \")[1] == \"Hour\"):\n",
    "                        minAgeStudy = float(int(minAgeStudy.split(\" \")[0]) * 0.000114)\n",
    "                minAgeStudy = float(minAgeStudy)\n",
    "\n",
    "                ## MaxAge\n",
    "                maxAgeStudy = dictionaryAgesDocs[k[1]][1].replace(\" Years\", \"\").replace(\" Year\", \"\").replace(\"N/A\", \"-1\")\n",
    "                if len(maxAgeStudy.split(\" \")) > 1:\n",
    "                    if (maxAgeStudy.split(\" \")[1] == \"Months\") or (maxAgeStudy.split(\" \")[1] == \"Month\"):\n",
    "                        #Caso tenha idade minima com meses\n",
    "                        maxAgeStudy = int(maxAgeStudy.split(\" \")[0])/12\n",
    "                    elif (maxAgeStudy.split(\" \")[1] == \"Weeks\") or (maxAgeStudy.split(\" \")[1] == \"Week\") :\n",
    "                        maxAgeStudy = float(maxAgeStudy.split(\" \")[0]) * 0.019165\n",
    "                    elif (maxAgeStudy.split(\" \")[1] == \"Days\") or (maxAgeStudy.split(\" \")[1] == \"Day\"):\n",
    "                        maxAgeStudy = float(int(maxAgeStudy.split(\" \")[0]) * 0.002738)\n",
    "                    elif (maxAgeStudy.split(\" \")[1] == \"Hours\") or (maxAgeStudy.split(\" \")[1] == \"Hour\"):\n",
    "                        maxAgeStudy = float(int(maxAgeStudy.split(\" \")[0]) * 0.000114)\n",
    "            \n",
    "                maxAgeStudy = float(maxAgeStudy)\n",
    "\n",
    "                if (ageQuery >= minAgeStudy and ageQuery <= maxAgeStudy) or (minAgeStudy == -1 and ageQuery <= maxAgeStudy) or (maxAgeStudy == -1 and ageQuery >= minAgeStudy):\n",
    "                    \n",
    "                    #TODO usar com mulktiplicacao de matizes\n",
    "                    contaComCoeficientes = 0\n",
    "                    j = 0\n",
    "                    for coef in coeficientes:\n",
    "                        contaComCoeficientes += coef[j]*v[j]\n",
    "                        j +=1\n",
    "                    docScores.append(contaComCoeficientes)\n",
    "                    docIds.append(k[1])\n",
    "                            \n",
    "                    #results_ord = results.sort_values(by=['score'], ascending = False)\n",
    "                    #listaDocscores.append(results_ord)\n",
    "                    #query ainda nao foi posta\n",
    "                    if k[0] not in dicQueryDocs:  \n",
    "                        \n",
    "                        contaComCoeficientes = 0\n",
    "                        j = 0\n",
    "                        for coef in coeficientes:\n",
    "                            contaComCoeficientes += coef[j]*v[j]\n",
    "                            j +=1\n",
    "                        docScores.append(contaComCoeficientes)\n",
    "                        docIds.append(k[1])\n",
    "                        \n",
    "\n",
    "                        #dataframe\n",
    "                        dicQueryDocs[i]= [(k[1], contaComCoeficientes)]\n",
    "                    \n",
    "                    #query ja esta no dicionario\n",
    "                    else:\n",
    "                        \n",
    "                        contaComCoeficientes = 0\n",
    "                        j = 0\n",
    "                        for coef in coeficientes:\n",
    "                            contaComCoeficientes += coef[j]*v[j]\n",
    "                            j +=1\n",
    "                        docScores.append(contaComCoeficientes)\n",
    "                        docIds.append(k[1])\n",
    "\n",
    "                        dicQueryDocs[i].append((k[1], contaComCoeficientes))\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    #repetir id da query\n",
    "    caseIdRep = [i] * len(docIds)\n",
    "    results = pd.DataFrame(list(zip(caseIdRep, docIds, docScores)), columns = ['caseid', '_id', 'score'])\n",
    "    results_ord = results.sort_values(by=['score'], ascending = False)\n",
    "    listaDocsFinal.append(results_ord)   \n",
    "    \n",
    "    [p10, recall, ap, ndcg5, mrr] = eval.eval(results_ord, i)\n",
    "    #Para fazer as medias dos prints\n",
    "    allP10s.append(p10)\n",
    "    allMrr.append(mrr)\n",
    "    allNdcg5.append(ndcg5)\n",
    "    allAp.append(ap)\n",
    "    allRecall.append(recall)\n",
    "\n",
    "    #Para fazer plot de P10-CaseId e AP-Case id (os pacientes com mais matches)\n",
    "    dictCaseIDP10[i] = p10\n",
    "    dictCaseAP[i] = ap\n",
    "\n",
    "    [precision_11pointLETORUni, recall_11pointLETORUni, total_relv_ret] = eval.evalPR(results_ord, i)\n",
    "    if (np.shape(recall_11pointLETORUni) != (0,)):\n",
    "        avg_precision_11pointLETORUni = avg_precision_11pointLETORUni + precision_11pointLETORUni\n",
    "\n",
    "\n",
    "averageAllP10s, averageAllMrr, averageNdcg5, averageAp, averageRecall = graficos.calculateAvgMetrics(allP10s, allMrr, allNdcg5, allAp, len(class_test), allRecall)\n",
    "graficos.printMetrics(averageAllP10s, averageAllMrr, averageNdcg5, averageAp, averageRecall)\n",
    "graficos.makePrecisionRecall(recall_11pointLETORUni, avg_precision_11pointLETORUni, len(class_test), None, \"BERT: Precision-Recall w/ Ngram: 1\")\n",
    "graficos.makeIDP10Graphic(dictCaseIDP10, \"BERT: P10/CaseID w/ Ngram: 1\", 12)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1897f3da715540eee82608773464ac44b6ce477f4187a6fe1d81b33c9f7e53b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
